{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "711bbbf9-2bb0-464e-a3dd-b900b07f970f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "711bbbf9-2bb0-464e-a3dd-b900b07f970f",
    "outputId": "cfb39743-e49f-4de4-8ab9-011f2f61d286"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Simple Neural Machine Translation (NMT)\\n• Build a basic sequence-to-sequence model using Python libraries like TensorFlow or\\nKeras.\\n• Use small parallel datasets (e.g., English-French sentence pairs) for training.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Simple Neural Machine Translation (NMT)\n",
    "• Build a basic sequence-to-sequence model using Python libraries like TensorFlow or\n",
    "Keras.\n",
    "• Use small parallel datasets (e.g., English-French sentence pairs) for training.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bff2d3c-6033-4812-858f-9e0041e313b3",
   "metadata": {
    "id": "7bff2d3c-6033-4812-858f-9e0041e313b3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c813cf00-906c-4b36-a53f-257c23e9e4aa",
   "metadata": {
    "id": "c813cf00-906c-4b36-a53f-257c23e9e4aa"
   },
   "outputs": [],
   "source": [
    "en_data = pd.read_csv(\"cleaned_small_vocab_en.csv\", header=None, on_bad_lines='skip', quoting=3)[0]\n",
    "fr_data = pd.read_csv(\"cleaned_small_vocab_fr.csv\", header=None, on_bad_lines='skip', quoting=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932bd677-16f7-4632-ab6e-164f9afeda10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "932bd677-16f7-4632-ab6e-164f9afeda10",
    "outputId": "56b22917-7c3d-45e0-e795-a034c6ba6e55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             \"new jersey is sometimes quiet during autumn \n",
       "1         \"the united states is usually chilly during july \n",
       "2                \"california is usually quiet during march \n",
       "3         \"the united states is sometimes mild during june \n",
       "4                     \"your least liked fruit is the grape \n",
       "                                ...                        \n",
       "118055                  \"france is never busy during march \n",
       "118056         \"india is sometimes beautiful during spring \n",
       "118057                   \"india is never wet during summer \n",
       "118058              \"france is never chilly during january \n",
       "118059                   \"the orange is her favorite fruit \n",
       "Name: 0, Length: 118060, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "627c5bdb-5b02-4f6a-8e40-3b87c6fec2c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "627c5bdb-5b02-4f6a-8e40-3b87c6fec2c9",
    "outputId": "831ad7d5-54b6-4607-b082-1c6635c1372e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         \"new jersey est parfois calme pendant l' automne \n",
       "1         \"les états-unis est généralement froid en juil...\n",
       "2               \"california est généralement calme en mars \n",
       "3               \"les états-unis est parfois légère en juin \n",
       "4                    \"votre moins aimé fruit est le raisin \n",
       "                                ...                        \n",
       "135821               \"la france est jamais occupée en mars \n",
       "135822             \"l' inde est parfois belle au printemps \n",
       "135823          \"l' inde est jamais mouillé pendant l' été \n",
       "135824              \"la france est jamais froid en janvier \n",
       "135825                     \"l'orange est son fruit préféré \n",
       "Name: 0, Length: 135826, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2531b53d-7af4-4189-b639-02786437eee7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2531b53d-7af4-4189-b639-02786437eee7",
    "outputId": "60b0bc38-bea5-4692-edc0-f6f684c86cc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa321342-5488-436d-8c2c-4b8aa6b895d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa321342-5488-436d-8c2c-4b8aa6b895d2",
    "outputId": "b9ce4ad8-bbe0-44a9-94db-9df62ab7a644"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdb21407-d327-4991-be04-a9c01f3125a4",
   "metadata": {
    "id": "cdb21407-d327-4991-be04-a9c01f3125a4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ae3923-6ed3-42d8-a6c5-25a617791bd1",
   "metadata": {
    "id": "50ae3923-6ed3-42d8-a6c5-25a617791bd1"
   },
   "outputs": [],
   "source": [
    "en_tokenizer = Tokenizer()\n",
    "en_tokenizer.fit_on_texts(en_data)\n",
    "en_sequences = en_tokenizer.texts_to_sequences(en_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "462826ea-b181-487d-8803-25a9accd2db8",
   "metadata": {
    "id": "462826ea-b181-487d-8803-25a9accd2db8"
   },
   "outputs": [],
   "source": [
    "fr_tokenizer = Tokenizer()\n",
    "fr_tokenizer.fit_on_texts(fr_data)\n",
    "fr_sequences = fr_tokenizer.texts_to_sequences(fr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f814466c-77b1-4c64-be4d-5f539884b33e",
   "metadata": {
    "id": "f814466c-77b1-4c64-be4d-5f539884b33e"
   },
   "outputs": [],
   "source": [
    "en_max_len = max(len(seq) for seq in en_sequences)\n",
    "fr_max_len = max(len(seq) for seq in fr_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08855db0-ae58-47ba-8f4e-da41e3dd934f",
   "metadata": {
    "id": "08855db0-ae58-47ba-8f4e-da41e3dd934f"
   },
   "outputs": [],
   "source": [
    "en_sequences = pad_sequences(en_sequences, maxlen=en_max_len, padding='post')\n",
    "fr_sequences = pad_sequences(fr_sequences, maxlen=fr_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10deaf48-3c66-426f-b888-a036f48f14c4",
   "metadata": {
    "id": "10deaf48-3c66-426f-b888-a036f48f14c4"
   },
   "outputs": [],
   "source": [
    "en_vocab_size = len(en_tokenizer.word_index) + 1\n",
    "fr_vocab_size = len(fr_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "457faa93-1d45-48eb-8099-6fa8ac2227dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "457faa93-1d45-48eb-8099-6fa8ac2227dd",
    "outputId": "5e6a0ef0-07e8-49db-de33-30b49d81d210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 199\n",
      "French Vocabulary Size: 333\n",
      "Max Length (English): 11\n",
      "Max Length (French): 15\n"
     ]
    }
   ],
   "source": [
    "print(\"English Vocabulary Size:\", en_vocab_size)\n",
    "print(\"French Vocabulary Size:\", fr_vocab_size)\n",
    "print(\"Max Length (English):\", en_max_len)\n",
    "print(\"Max Length (French):\", fr_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51af0593-647b-4ff9-b8f3-fb10734af97d",
   "metadata": {
    "id": "51af0593-647b-4ff9-b8f3-fb10734af97d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5dd5054-3fac-4093-956f-353dacf96212",
   "metadata": {
    "id": "f5dd5054-3fac-4093-956f-353dacf96212"
   },
   "outputs": [],
   "source": [
    "# Step 1: Define the Encoder\n",
    "embedding_dim = 256\n",
    "units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "782e474a-220a-4b88-9bb0-40534c577eb2",
   "metadata": {
    "id": "782e474a-220a-4b88-9bb0-40534c577eb2"
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(en_max_len,))\n",
    "encoder_embedding = Embedding(en_vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_lstm, state_h, state_c = LSTM(units, return_state=True)(encoder_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed361815-37e3-4738-9bfd-f68282847cc3",
   "metadata": {
    "id": "ed361815-37e3-4738-9bfd-f68282847cc3"
   },
   "outputs": [],
   "source": [
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fac45aba-5d12-4493-85f6-b26ac175cc8c",
   "metadata": {
    "id": "fac45aba-5d12-4493-85f6-b26ac175cc8c"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(fr_max_len - 1,))  # Adjust the input shape here\n",
    "decoder_embedding = Embedding(fr_vocab_size, embedding_dim)(decoder_inputs)\n",
    "decoder_lstm, _, _ = LSTM(units, return_sequences=True, return_state=True)(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(fr_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0083445f-6bdf-40cf-b7c2-5380d8dba38f",
   "metadata": {
    "id": "0083445f-6bdf-40cf-b7c2-5380d8dba38f"
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34036589-3508-47a1-9d1d-3e3a9c7ad39c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "34036589-3508-47a1-9d1d-3e3a9c7ad39c",
    "outputId": "d61ca7df-d1de-49d8-d8ad-d8dfe757c018",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">50,944</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">85,248</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]        │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]        │                 │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">333</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">170,829</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │          \u001b[38;5;34m50,944\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │          \u001b[38;5;34m85,248\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │       \u001b[38;5;34m1,574,912\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│                               │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]        │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,  │       \u001b[38;5;34m1,574,912\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                               │ \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]        │                 │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m333\u001b[0m)           │         \u001b[38;5;34m170,829\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,456,845</span> (13.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,456,845\u001b[0m (13.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,456,845</span> (13.19 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,456,845\u001b[0m (13.19 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "878365c9-c4f1-495d-a49e-c391088fca6a",
   "metadata": {
    "id": "878365c9-c4f1-495d-a49e-c391088fca6a"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare decoder input data (French sentences shifted by one timestep)\n",
    "decoder_input_data = fr_sequences[:, :-1]  # Input: all but the last token\n",
    "decoder_output_data = fr_sequences[:, 1:]  # Output: all but the first token\n",
    "\n",
    "# Ensure that en_sequences and decoder_input_data have the same number of samples\n",
    "min_samples = min(len(en_sequences), len(decoder_input_data))\n",
    "en_sequences = en_sequences[:min_samples]\n",
    "decoder_input_data = decoder_input_data[:min_samples]\n",
    "decoder_output_data = decoder_output_data[:min_samples]\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "X_train_val, X_test, decoder_input_train_val, decoder_input_test = train_test_split(\n",
    "    en_sequences, decoder_input_data, test_size=0.2, random_state=42\n",
    ")\n",
    "decoder_output_train_val, decoder_output_test = train_test_split(\n",
    "    decoder_output_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Further split train_val into train and validation sets\n",
    "X_train, X_val, decoder_input_train, decoder_input_val = train_test_split(\n",
    "    X_train_val, decoder_input_train_val, test_size=0.2, random_state=42\n",
    ")\n",
    "decoder_output_train, decoder_output_val = train_test_split(\n",
    "    decoder_output_train_val, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Reshape the target data\n",
    "decoder_output_train = np.expand_dims(decoder_output_train, -1)\n",
    "decoder_output_val = np.expand_dims(decoder_output_val, -1)\n",
    "decoder_output_test = np.expand_dims(decoder_output_test, -1)  # Reshape test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7da53ff-2234-473f-a394-13db31d880fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7da53ff-2234-473f-a394-13db31d880fa",
    "outputId": "8ecfcdb3-95b6-4786-8fc1-f6ece56b2df0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1523s\u001b[0m 1s/step - accuracy: 0.7565 - loss: 1.0415 - val_accuracy: 0.8237 - val_loss: 0.4868\n",
      "Epoch 2/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1247s\u001b[0m 1s/step - accuracy: 0.8256 - loss: 0.4803 - val_accuracy: 0.8266 - val_loss: 0.4738\n",
      "Epoch 3/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1087s\u001b[0m 899ms/step - accuracy: 0.8274 - loss: 0.4689 - val_accuracy: 0.8278 - val_loss: 0.4675\n",
      "Epoch 4/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m532s\u001b[0m 451ms/step - accuracy: 0.8281 - loss: 0.4633 - val_accuracy: 0.8264 - val_loss: 0.4629\n",
      "Epoch 5/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1598s\u001b[0m 1s/step - accuracy: 0.8290 - loss: 0.4596 - val_accuracy: 0.8276 - val_loss: 0.4631\n",
      "Epoch 6/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 301ms/step - accuracy: 0.8292 - loss: 0.4570 - val_accuracy: 0.8287 - val_loss: 0.4600\n",
      "Epoch 7/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 222ms/step - accuracy: 0.8295 - loss: 0.4547 - val_accuracy: 0.8293 - val_loss: 0.4583\n",
      "Epoch 8/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 214ms/step - accuracy: 0.8309 - loss: 0.4531 - val_accuracy: 0.8276 - val_loss: 0.4586\n",
      "Epoch 9/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 229ms/step - accuracy: 0.8305 - loss: 0.4512 - val_accuracy: 0.8298 - val_loss: 0.4576\n",
      "Epoch 10/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 225ms/step - accuracy: 0.8310 - loss: 0.4503 - val_accuracy: 0.8302 - val_loss: 0.4553\n",
      "Epoch 11/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 222ms/step - accuracy: 0.8315 - loss: 0.4483 - val_accuracy: 0.8287 - val_loss: 0.4561\n",
      "Epoch 12/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 223ms/step - accuracy: 0.8324 - loss: 0.4474 - val_accuracy: 0.8283 - val_loss: 0.4563\n",
      "Epoch 13/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 226ms/step - accuracy: 0.8323 - loss: 0.4464 - val_accuracy: 0.8292 - val_loss: 0.4560\n",
      "Epoch 14/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 229ms/step - accuracy: 0.8320 - loss: 0.4458 - val_accuracy: 0.8283 - val_loss: 0.4556\n",
      "Epoch 15/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 226ms/step - accuracy: 0.8331 - loss: 0.4438 - val_accuracy: 0.8295 - val_loss: 0.4562\n",
      "Epoch 16/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 221ms/step - accuracy: 0.8331 - loss: 0.4434 - val_accuracy: 0.8291 - val_loss: 0.4551\n",
      "Epoch 17/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m785s\u001b[0m 665ms/step - accuracy: 0.8336 - loss: 0.4419 - val_accuracy: 0.8304 - val_loss: 0.4556\n",
      "Epoch 18/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m664s\u001b[0m 562ms/step - accuracy: 0.8344 - loss: 0.4409 - val_accuracy: 0.8278 - val_loss: 0.4563\n",
      "Epoch 19/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m717s\u001b[0m 607ms/step - accuracy: 0.8347 - loss: 0.4395 - val_accuracy: 0.8295 - val_loss: 0.4559\n",
      "Epoch 20/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m665s\u001b[0m 563ms/step - accuracy: 0.8357 - loss: 0.4375 - val_accuracy: 0.8273 - val_loss: 0.4579\n",
      "Epoch 21/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m701s\u001b[0m 594ms/step - accuracy: 0.8361 - loss: 0.4360 - val_accuracy: 0.8284 - val_loss: 0.4590\n",
      "Epoch 22/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m687s\u001b[0m 582ms/step - accuracy: 0.8366 - loss: 0.4349 - val_accuracy: 0.8284 - val_loss: 0.4595\n",
      "Epoch 23/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m704s\u001b[0m 596ms/step - accuracy: 0.8384 - loss: 0.4311 - val_accuracy: 0.8274 - val_loss: 0.4613\n",
      "Epoch 24/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m718s\u001b[0m 608ms/step - accuracy: 0.8400 - loss: 0.4288 - val_accuracy: 0.8275 - val_loss: 0.4637\n",
      "Epoch 25/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m785s\u001b[0m 665ms/step - accuracy: 0.8420 - loss: 0.4235 - val_accuracy: 0.8268 - val_loss: 0.4668\n",
      "Epoch 26/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1075s\u001b[0m 910ms/step - accuracy: 0.8439 - loss: 0.4194 - val_accuracy: 0.8279 - val_loss: 0.4686\n",
      "Epoch 27/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2838s\u001b[0m 2s/step - accuracy: 0.8465 - loss: 0.4140 - val_accuracy: 0.8260 - val_loss: 0.4743\n",
      "Epoch 28/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m525s\u001b[0m 444ms/step - accuracy: 0.8495 - loss: 0.4074 - val_accuracy: 0.8260 - val_loss: 0.4771\n",
      "Epoch 29/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m721s\u001b[0m 611ms/step - accuracy: 0.8529 - loss: 0.4001 - val_accuracy: 0.8246 - val_loss: 0.4837\n",
      "Epoch 30/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 393ms/step - accuracy: 0.8567 - loss: 0.3918 - val_accuracy: 0.8243 - val_loss: 0.4896\n",
      "Epoch 31/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 262ms/step - accuracy: 0.8602 - loss: 0.3836 - val_accuracy: 0.8227 - val_loss: 0.4972\n",
      "Epoch 32/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 279ms/step - accuracy: 0.8637 - loss: 0.3754 - val_accuracy: 0.8226 - val_loss: 0.5032\n",
      "Epoch 33/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 246ms/step - accuracy: 0.8679 - loss: 0.3659 - val_accuracy: 0.8230 - val_loss: 0.5140\n",
      "Epoch 34/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 241ms/step - accuracy: 0.8721 - loss: 0.3564 - val_accuracy: 0.8216 - val_loss: 0.5241\n",
      "Epoch 35/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 272ms/step - accuracy: 0.8753 - loss: 0.3475 - val_accuracy: 0.8208 - val_loss: 0.5347\n",
      "Epoch 36/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 263ms/step - accuracy: 0.8804 - loss: 0.3360 - val_accuracy: 0.8195 - val_loss: 0.5429\n",
      "Epoch 37/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 251ms/step - accuracy: 0.8843 - loss: 0.3257 - val_accuracy: 0.8184 - val_loss: 0.5590\n",
      "Epoch 38/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 354ms/step - accuracy: 0.8883 - loss: 0.3161 - val_accuracy: 0.8190 - val_loss: 0.5689\n",
      "Epoch 39/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m842s\u001b[0m 713ms/step - accuracy: 0.8927 - loss: 0.3068 - val_accuracy: 0.8181 - val_loss: 0.5811\n",
      "Epoch 40/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m750s\u001b[0m 597ms/step - accuracy: 0.8962 - loss: 0.2973 - val_accuracy: 0.8170 - val_loss: 0.5962\n",
      "Epoch 41/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m720s\u001b[0m 577ms/step - accuracy: 0.9006 - loss: 0.2857 - val_accuracy: 0.8165 - val_loss: 0.6105\n",
      "Epoch 42/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m661s\u001b[0m 560ms/step - accuracy: 0.9036 - loss: 0.2779 - val_accuracy: 0.8159 - val_loss: 0.6219\n",
      "Epoch 43/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1604s\u001b[0m 1s/step - accuracy: 0.9072 - loss: 0.2680 - val_accuracy: 0.8160 - val_loss: 0.6377\n",
      "Epoch 44/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 580ms/step - accuracy: 0.9105 - loss: 0.2597 - val_accuracy: 0.8152 - val_loss: 0.6534\n",
      "Epoch 45/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 440ms/step - accuracy: 0.9141 - loss: 0.2508 - val_accuracy: 0.8145 - val_loss: 0.6660\n",
      "Epoch 46/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 245ms/step - accuracy: 0.9174 - loss: 0.2423 - val_accuracy: 0.8142 - val_loss: 0.6802\n",
      "Epoch 47/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 238ms/step - accuracy: 0.9203 - loss: 0.2341 - val_accuracy: 0.8132 - val_loss: 0.6922\n",
      "Epoch 48/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m569s\u001b[0m 447ms/step - accuracy: 0.9234 - loss: 0.2252 - val_accuracy: 0.8122 - val_loss: 0.7125\n",
      "Epoch 49/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m798s\u001b[0m 675ms/step - accuracy: 0.9256 - loss: 0.2192 - val_accuracy: 0.8126 - val_loss: 0.7281\n",
      "Epoch 50/50\n",
      "\u001b[1m1181/1181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m936s\u001b[0m 793ms/step - accuracy: 0.9287 - loss: 0.2114 - val_accuracy: 0.8126 - val_loss: 0.7372\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 \n",
    "\n",
    "epochs = 50\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train, decoder_input_train], decoder_output_train,\n",
    "    validation_data=([X_val, decoder_input_val], decoder_output_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0ed0f64-bf88-4801-b1e4-156a2a3ce8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a file\n",
    "model.save('seq2seq_translation_model.h5')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbbbf312-9da0-441a-a41c-02b806c3c623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('seq2seq_translation_model.h5')\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d54f4e4e-0f7b-42d0-aab5-1a220b818fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m591/591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 119ms/step - accuracy: 0.8129 - loss: 0.7395\n",
      "Validation Loss: 0.7371774315834045\n",
      "Validation Accuracy: 0.8125613331794739\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate([X_val, decoder_input_val], decoder_output_val, verbose=1)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc4f4a1-8c37-401f-9205-bbb7fd5672c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
